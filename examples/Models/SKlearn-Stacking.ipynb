{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = get_file('cifar10_samples.npz',\n",
    "            'https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10_samples.npz')\n",
    "data = np.load(data_path)\n",
    "x_train, y_train, x_val, y_val = [item[1] for item in data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "#Source Code: https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10SimpleCNN.h5\n",
    "model_path1 = get_file('cifar10SimpleCNN.h5',\n",
    "            'https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10SimpleCNN.h5')\n",
    "model1 = keras.models.load_model(model_path1)\n",
    "\n",
    "#Source Code: https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10SimpleCNN2.py\n",
    "model_path2 = get_file('cifar10SimpleCNN2.h5',\n",
    "            'https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10SimpleCNN2.h5')\n",
    "model2 = keras.models.load_model(model_path2)\n",
    "\n",
    "#Source Code: https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10keras.py\n",
    "model_path3 = get_file('cifar10keras.h5',\n",
    "            'https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10keras.h5')\n",
    "model3 = keras.models.load_model(model_path3)\n",
    "\n",
    "#Source Code: https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10vgg.py\n",
    "model_path4 = get_file('cifar10vgg.h5',\n",
    "            'https://github.com/jcborges/DeepStack/releases/download/Cifar10/cifar10vgg.h5')\n",
    "model4 = keras.models.load_model(model_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepstack.base import KerasMember\n",
    "member1 = KerasMember(name=\"model1\", keras_model=model1, train_batches=(x_train, y_train), val_batches=(x_val, y_val))\n",
    "member2 = KerasMember(name=\"model2\", keras_model=model2, train_batches=(x_train, y_train), val_batches=(x_val, y_val))\n",
    "member3 = KerasMember(name=\"model3\", keras_model=model3, train_batches=(x_train, y_train), val_batches=(x_val, y_val))\n",
    "member4 = KerasMember(name=\"model4\", keras_model=model4, train_batches=(x_train, y_train), val_batches=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepstack.ensemble import Ensemble\n",
    "\n",
    "class StackEnsemble(Ensemble):\n",
    "    def __init__(self, model=None):\n",
    "        \"\"\"\n",
    "        Constructor of a Stacking Ensemble.\n",
    "        Args:\n",
    "            model: ensemble model which should serve as meta-model.\n",
    "                `sklearn.ensemble.RandomForestRegressor` per default for predicting class probabilities.\n",
    "            members (list): ensemble Members to add to the Stack\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        if model is None:\n",
    "            self.model = RandomForestRegressor(n_estimators=100, max_depth=3, n_jobs=20)\n",
    "        # Initialize Parameters:\n",
    "        self.members = []\n",
    "        self._nmembers = 0\n",
    "        self.predictions = None\n",
    "        self._y_squeezed = False  # Flags if labels dimension must be squeezed\n",
    "\n",
    "    def __repr__(self):\n",
    "        reps = [member.name for member in self.members]\n",
    "        return \"<StackEnsemble: [\" + \", \".join(reps) + \"]>\"\n",
    "\n",
    "    def __str__(self):\n",
    "        reps = [member.name for member in self.members]\n",
    "        return \"StackEnsemble: with\" + \\\n",
    "            str(self._nmembers) + \" Base-Learners [\" + \", \".join(reps) + \"]\"\n",
    "\n",
    "    def add_members(self, members):\n",
    "        \"\"\"\n",
    "        Adds ensemble Members to the Stack\n",
    "        Args:\n",
    "            members: a list containing instances of class `Member`\n",
    "        \"\"\"\n",
    "        for member in members:\n",
    "            self.add_member(member)\n",
    "        self._test()\n",
    "\n",
    "    def add_member(self, member):\n",
    "        \"\"\"\n",
    "        Adds a ensemble Member to the Stack\n",
    "        Args:\n",
    "            member: an instance of class `Member`\n",
    "        \"\"\"\n",
    "        self.members.append(member)\n",
    "        self._nmembers += 1\n",
    "        if member.val_probs is None:\n",
    "            try:\n",
    "                member.val_probs = member._calculate_val_predictions()\n",
    "            except Exception as e:\n",
    "                warnings.warn(str(e))\n",
    "        if member.train_probs is None:\n",
    "            try:\n",
    "                member.train_probs = member._calculate_train_predictions()\n",
    "            except Exception as e:\n",
    "                warnings.warn(str(e))\n",
    "\n",
    "    def fit(self, X=None, y=None, kwargs={}):\n",
    "        \"\"\"\n",
    "        Trains the meta-model\n",
    "        Args:\n",
    "            X: training data for meta-learner\n",
    "            y: training classes for meta-learner\n",
    "            kwargs: further arguments for the fit function\n",
    "        \"\"\"\n",
    "        assert(len(self.members) > 1)\n",
    "        # Assumption: all members have same train_batches.classes\n",
    "        if X is None or y is None:\n",
    "            return self._fit_train()\n",
    "        if X.ndim >= 3:\n",
    "            X = X.reshape(X.shape[0], np.prod(X.shape[1::]))\n",
    "        try:\n",
    "            self._y_squeezed = False\n",
    "            return self.model.fit(X, y, **kwargs)\n",
    "        except ValueError:  # Normally bad input shape for non-multi-output models\n",
    "            self._y_squeezed = True\n",
    "            y_flat = np.argmax(y, axis=1)\n",
    "            return self.model.fit(X, y_flat, **kwargs)\n",
    "\n",
    "    def predict(self, X=None, predict_proba=False, kwargs={}):\n",
    "        \"\"\"\n",
    "        Meta-Model prediction for the class' probabilities as a regression\n",
    "        problem.\n",
    "        Args:\n",
    "            X: input data to be predicted\n",
    "            kwargs: further arguments for prediction function\n",
    "            predict_proba: if should call method `predict_proba`\n",
    "                instead of `predict`.\n",
    "        Returns:\n",
    "            the predicted probabilities as np.array\n",
    "        \"\"\"\n",
    "        if X is None:\n",
    "            X = self._get_pred_X()\n",
    "        if X.ndim == 3:\n",
    "            X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "        if (predict_proba or self._y_squeezed) and hasattr(self.model, 'predict_proba'):\n",
    "            self.predictions = self.model.predict_proba(X, **kwargs)\n",
    "            print(\"Calling predict_proba\")\n",
    "        elif hasattr(self.model, 'predict'):\n",
    "            self.predictions = self.model.predict(X, **kwargs)\n",
    "            print(\"Calling predict\")            \n",
    "        else:\n",
    "            raise ValueError(\"Model has no predict function\")\n",
    "        return np.array(self.predictions)\n",
    "\n",
    "    def describe(self, probabilities_val=None, metric=None,\n",
    "                 maximize=True):\n",
    "        \"\"\"\n",
    "        Prints information about the performance of base and meta learners\n",
    "        based on validation data.\n",
    "        Args:\n",
    "            probabilities_val: (optional) probabilities/prediction on\n",
    "                validation data\n",
    "            metric: (optional) evaluation metric function.\n",
    "                Default: `sklearn.metrics.roc_auc_score`\n",
    "            maximize: if metric should be maximized (otherwise minimized)\n",
    "        \"\"\"\n",
    "        best_score = float(\"-inf\") if maximize else float(\"inf\")\n",
    "        if metric is None:\n",
    "            metric = metrics.roc_auc_score\n",
    "        if probabilities_val is None:\n",
    "            probabilities_val = self._predict_val()\n",
    "        # Assumption: all members have same val_classes\n",
    "        val_classes = self.members[0].val_classes\n",
    "        for i in range(self._nmembers):\n",
    "            member = self.members[i]\n",
    "            model_score = _calculate_metric(member.val_classes, member.val_probs, metric)\n",
    "            max_flag = maximize and model_score > best_score\n",
    "            min_flag = not(maximize) and model_score < best_score\n",
    "            if max_flag or min_flag:\n",
    "                best_score = model_score\n",
    "            text = member.name + \" - {}: {:1.4f}\".format(\n",
    "                metric.__name__, model_score)\n",
    "            print(text)\n",
    "        ensemble_score = _calculate_metric(val_classes, probabilities_val, metric)\n",
    "        print(\"StackEnsemble {}: {:1.4f}\".format(\n",
    "            metric.__name__, ensemble_score))\n",
    "        return ensemble_score\n",
    "\n",
    "    def _get_X(self, attrname):\n",
    "        X = []\n",
    "        probs = getattr(self.members[0], attrname)\n",
    "        # Assumption: all members have same train_probs length\n",
    "        for i in range(len(probs)):\n",
    "            preds = []\n",
    "            for member in self.members:\n",
    "                preds.append(getattr(member, attrname)[i])\n",
    "            X.append(preds)\n",
    "        return np.array(X)\n",
    "\n",
    "    def _get_train_X(self):\n",
    "        return self._get_X(\"train_probs\")\n",
    "\n",
    "    def _get_val_X(self):\n",
    "        return self._get_X(\"val_probs\")\n",
    "\n",
    "    def _get_pred_X(self):\n",
    "        return self._get_X(\"submission_probs\")\n",
    "\n",
    "    def _fit_train(self):\n",
    "        return self.fit(self._get_train_X(), self.members[0].train_classes)\n",
    "\n",
    "    def _fit_submission(self):\n",
    "        \"\"\"\n",
    "        Fits model on training and validation data.\n",
    "        Useful when training the meta-learner for final submission prediction\n",
    "        \"\"\"\n",
    "        X1 = self._get_train_X()\n",
    "        X2 = self._get_val_X()\n",
    "        y1 = self.members[0].train_classes\n",
    "        y2 = self.members[0].val_classes\n",
    "        X = np.concatenate((X1, X2))\n",
    "        y = np.concatenate((y1, y2))\n",
    "        return self.fit(X, y)\n",
    "\n",
    "    def _predict_val(self):\n",
    "        return self.predict(self._get_val_X())\n",
    "\n",
    "    def _test(self):\n",
    "        \"\"\"\n",
    "        Test assumption that all members' classes have same shape and values.\n",
    "        Names should be unique.\n",
    "        This is an internal condition for class structures.\n",
    "        \"\"\"\n",
    "        if self._nmembers < 2:\n",
    "            return True\n",
    "        t1 = [(np.array_equal(self.members[i].train_classes,\n",
    "                              self.members[i + 1].train_classes))\n",
    "              for i in range(self._nmembers - 1)]\n",
    "        t2 = [(np.array_equal(self.members[i].val_classes,\n",
    "                              self.members[i + 1].val_classes))\n",
    "              for i in range(self._nmembers - 1)]\n",
    "        assert(np.sum(t1) == self._nmembers - 1)\n",
    "        assert(np.sum(t2) == self._nmembers - 1)\n",
    "        names = [self.members[i].name for i in range(self._nmembers)]\n",
    "        assert(len(list(names)) == len(set(names)))\n",
    "        return True\n",
    "\n",
    "    def save(self, folder=\"./premodels/\"):\n",
    "        \"\"\"\n",
    "        Saves meta-learner and base-learner of ensemble into folder / directory\n",
    "        Args:\n",
    "            folder: the folder where models should be saved to.\n",
    "                Create if not exists.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        [member.save(folder=folder) for member in self.members]\n",
    "        temp = self.members\n",
    "        # Reset base-learners. These are loaded idependently\n",
    "        self.members = None\n",
    "        self._nmembers = 0\n",
    "        joblib.dump(self, os.path.join(folder, \"stackensemble.joblib\"))\n",
    "        self.members = temp\n",
    "        self._nmembers = len(self.members)\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, folder=\"./premodels/\"):\n",
    "        \"\"\"\n",
    "        Loads meta-learner and base-learners from folder / directory\n",
    "        Args:\n",
    "            folder: directory where models should be loaded from\n",
    "        Returns:\n",
    "            loaded StackEnsemble with Members\n",
    "        \"\"\"\n",
    "        stack = joblib.load(os.path.join(folder, \"stackensemble.joblib\"))\n",
    "        stack.members = []\n",
    "        if folder[-1] != os.sep:\n",
    "            folder += os.sep\n",
    "        for fn in glob.glob(folder + \"**/\"):\n",
    "            member = Member.load(fn)\n",
    "            stack.add_member(member)\n",
    "        return stack\n",
    "\n",
    "\n",
    "def _calculate_metric(y_true, y_pred, metric=None):  # TODO: Refactor\n",
    "    if metric is None:\n",
    "        metric = metrics.roc_auc_score\n",
    "    try:\n",
    "        return metric(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        y_true_cat = to_categorical(y_true)\n",
    "        return metrics.roc_auc_score(y_true_cat, y_pred)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Classification Task\n",
    "    y_t = y_true\n",
    "    if y_true.ndim > 1:\n",
    "        y_t = np.argmax(y_true, axis=1)\n",
    "    y_p = y_pred\n",
    "    if y_pred.ndim > 1:\n",
    "        y_p = np.argmax(y_pred, axis=1)\n",
    "    return metric(y_t, y_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bgo2abt/PycharmProjects/scikit-learn/sklearn/linear_model/_logistic.py:931: ConvergenceWarning: lbfgs failed to converge (status=1): b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'. Increase the number of iterations.\n",
      "  n_iter_i = _check_optimize_result(solver, opt_res, max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling predict_proba\n",
      "model1 - accuracy_score: 0.6116\n",
      "model2 - accuracy_score: 0.6571\n",
      "model3 - accuracy_score: 0.5500\n",
      "model4 - accuracy_score: 0.6062\n",
      "StackEnsemble accuracy_score: 0.6969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6969"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "stack = StackEnsemble()\n",
    "stack.model = RandomForestClassifier(verbose=0, n_estimators=200, max_depth=15, n_jobs=20, min_samples_split=20)\n",
    "stack.add_members([member1, member2, member3, member4])\n",
    "\n",
    "estimators = [\n",
    "    ('rf2', RandomForestClassifier(verbose=0, n_estimators=200, max_depth=15, n_jobs=20, min_samples_split=30)),\n",
    "    ('etr2', ExtraTreesClassifier(verbose=0, n_estimators=200, max_depth=10, n_jobs=20, min_samples_split=20))\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stack.model = clf\n",
    "stack.fit()\n",
    "stack.describe(metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackEnsemble()\n",
    "stack.model = RandomForestRegressor(verbose=0, n_estimators=200, max_depth=15, n_jobs=20, min_samples_split=20)\n",
    "stack.add_members([member1, member2, member3, member4])\n",
    "stack.fit()\n",
    "stack.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackEnsemble()\n",
    "stack.model = RandomForestClassifier(verbose=0, n_estimators=200, max_depth=15, n_jobs=20, min_samples_split=20)\n",
    "stack.add_members([member1, member2, member3, member4])\n",
    "stack.fit()\n",
    "stack.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=stack._get_val_X()\n",
    "X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "tt=stack.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
